{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe795f66",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN) \n",
    "It is a simple and intuitive supervised machine learning algorithm used for classification and regression tasks. In classification, KNN predicts the class label of a new data point based on the majority class of its 'k' nearest neighbors in the feature space. The 'k' neighbors are determined by measuring distances, typically using Euclidean distance, between the new data point and all other data points in the training set. The algorithm does not make any assumptions about the underlying data distribution, making it versatile and suitable for various types of datasets. However, its performance may degrade with high-dimensional or noisy data, and it can be computationally expensive, especially with large datasets, as it requires storing and computing distances for all training samples during prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70727e",
   "metadata": {},
   "source": [
    "### Minkowski Distance:\n",
    "The Minkowski distance is a generalization of other distance measures such as Euclidean distance and Manhattan distance. It calculates the distance between two points in a multi-dimensional space. \n",
    "\n",
    "The Minkowski distance between two points \\( P \\) and \\( Q \\) in \\( n \\)-dimensional space is given by:\n",
    "\n",
    "$$ D(P, Q) = \\left( \\sum_{i=1}^{n} |x_i - y_i|^p \\right)^{\\frac{1}{p}} $$\n",
    "\n",
    "Where:\n",
    "- \\( x_i \\) and \\( y_i \\) are the \\( i \\)-th dimensions of points \\( P \\) and \\( Q \\) respectively.\n",
    "- \\( p \\) is a parameter that defines the order of the Minkowski distance. When \\( p = 1 \\), it is equivalent to Manhattan distance, and when \\( p = 2 \\), it is equivalent to Euclidean distance.\n",
    "\n",
    "### Euclidean Distance:\n",
    "The Euclidean distance is a measure of the straight-line distance between two points in Euclidean space. \n",
    "\n",
    "The Euclidean distance between two points \\( P \\) and \\( Q \\) in \\( n \\)-dimensional space is given by:\n",
    "\n",
    "$$ D(P, Q) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2} $$\n",
    "\n",
    "Where:\n",
    "- \\( x_i \\) and \\( y_i \\) are the \\( i \\)-th dimensions of points \\( P \\) and \\( Q \\) respectively.\n",
    "\n",
    "These distances are commonly used in various machine learning algorithms and data analysis tasks to quantify the similarity or dissimilarity between data points in a dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c5e7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   brightness  saturation Class\n",
      "0          40          20   Red\n",
      "1          50          50  Blue\n",
      "2          60          90  Blue\n",
      "3          10          25   Red\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating the data for traing\n",
    "# it is same as we saw exaple in previous class\n",
    "data = {\n",
    "    'brightness': [40, 50, 60, 10],\n",
    "    'saturation': [20, 50, 90, 25],\n",
    "    'Class': ['Red', 'Blue', 'Blue', 'Red']\n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddec993",
   "metadata": {},
   "source": [
    "### What is scikit-learn?\n",
    "\n",
    "Scikit-learn, often abbreviated as **sklearn**, is one of the most popular and widely used machine learning libraries in Python. It provides simple and efficient tools for data mining and data analysis, built on top of NumPy, SciPy, and matplotlib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78fa1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kNN from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Creating the DataFrame for testing \n",
    "X_test = pd.DataFrame({'brightness': [20], 'saturation': [35]})\n",
    "\n",
    "\n",
    "# Splitting the data into features and target variable\n",
    "X = df[['brightness', 'saturation']]\n",
    "y = df['Class']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2f6f6",
   "metadata": {},
   "source": [
    "### Feature Matrix (X)\n",
    "\n",
    "The term \"X\" typically refers to the feature matrix, also known as the design matrix or predictor matrix. This matrix contains the features or attributes of the dataset used for training the model.\n",
    "\n",
    "Each row of the feature matrix corresponds to a single sample or data point (Feature vector), and each column corresponds to a feature or attribute of that sample. Therefore, the dimensions of the feature matrix $ X $ are typically $  m \\times n  $, where $ m $ is the number of samples and $ n $ is the number of features.\n",
    "\n",
    "For example, in a dataset with $ m $ samples and $ n $ features, the feature matrix $ X $ would look like this:\n",
    "\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\dots & x_{1n} \\\\\n",
    "x_{21} & x_{22} & \\dots & x_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{m1} & x_{m2} & \\dots & x_{mn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where $ x_{ij} $ represents the value of the $ j $-th feature of the $ i $-th sample.\n",
    "\n",
    "So, in the context of scikit-learn or any machine learning library, when you refer to the feature matrix $ X $, you are essentially talking about the data matrix containing the features of your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca6f29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brightness</th>\n",
       "      <th>saturation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brightness  saturation\n",
       "0          40          20\n",
       "1          50          50\n",
       "2          60          90\n",
       "3          10          25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # feature matrix  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb549d",
   "metadata": {},
   "source": [
    "### Target Variable (y)\n",
    "\n",
    "The term \"y\" typically refers to the target variable or the response variable. It represents the labels or outcomes associated with the samples in the dataset.\n",
    "\n",
    "The target variable $ y $ is usually a one-dimensional array or a column vector containing the labels or outcomes corresponding to each sample in the feature matrix $ X $.\n",
    "\n",
    "For classification problems, $ y $ contains discrete class labels or categories assigned to each sample i.e. (Red, Blue). In regression problems, $ y $ contains continuous values representing the target variable to be predicted for each sample i.e. 2500,35000,400000,200000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e998ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Red\n",
       "1    Blue\n",
       "2    Blue\n",
       "3     Red\n",
       "Name: Class, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6b856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted label for sample: \n",
      "\n",
      "    brightness  saturation\n",
      "0          20          35  \n",
      "\n",
      "is  ['Red']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Creating and training the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predicting the labels for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print (\"The predicted label for sample: \\n\\n\",X_test,\" \\n\\nis \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb220a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances to nearest neighbors: [[14.14213562 25.         33.54101966]]\n",
      "Indices for nearest neighbors: [[3 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Finding the distances and indices of the k nearest neighbors\n",
    "distances, indices = knn.kneighbors(X_test)\n",
    "\n",
    "print(\"Distances to nearest neighbors:\", distances)\n",
    "print(\"Indices for nearest neighbors:\", indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
